import logging
import re
import torch
import csv
import os
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from telegram import ReplyKeyboardMarkup


logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)
TOKEN = ("Paste token")

LOG_DIR = "dir to save logs"
MODEL_PATH = "path where you storage your Transformer model"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

os.makedirs(LOG_DIR, exist_ok=True)


def clean_tweet(text):
    text = re.sub(r'http\S+', '', text)  # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ ÑÑÑ‹Ð»Ð¾Ðº
    text = re.sub(r'@\w+', '', text)  # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹
    text = re.sub(r'#', '', text)
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^A-Za-z0-9\s.,:;?!\-\']', '', text)
    text = text.strip()
    return text


def log_request(user_data: dict):
    today = datetime.now().strftime("%Y-%m-%d")
    log_file = os.path.join(LOG_DIR, f"requests_{today}.csv")

    user_data.setdefault("username", "")
    user_data.setdefault("first_name", "")

    fieldnames = ["timestamp", "user_id", "username", "first_name", "text", "prediction"]

    try:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        with open(log_file, "a", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð¿ÑƒÑÑ‚ Ð»Ð¸ Ñ„Ð°Ð¹Ð»
            if os.stat(log_file).st_size == 0:
                writer.writeheader()
            writer.writerow(user_data)
        logger.info(f"Ð—Ð°Ð¿Ð¸ÑÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð°: {user_data}")
    except Exception as e:
        logger.error(f"ÐžÐ¨Ð˜Ð‘ÐšÐ Ð—ÐÐŸÐ˜Ð¡Ð˜: {str(e)}", exc_info=True)


try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)
    model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_PATH,
        local_files_only=True,
        use_safetensors=True,
        ignore_mismatched_sizes=True
    ).to(DEVICE)
except Exception as e:
    logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")
    exit(1)


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.message.from_user
    text = update.message.text
    timestamp = datetime.now().isoformat()
    prediction = None

    # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
    user_info = {
        "user_id": user.id,
        "username": user.username or "",  # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° None
        "first_name": user.first_name or "",  # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° None
    }

    try:
        inputs = tokenizer(
            clean_tweet(text),
            truncation=True,
            padding="max_length",
            max_length=256,
            return_tensors="pt"
        ).to(DEVICE)

        with torch.no_grad():
            outputs = model(**inputs)
            prediction = torch.argmax(outputs.logits).item()

        response = "â›” Disaster detected!" if prediction == 1 else "âœ… No disaster"

    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {str(e)}", exc_info=True)
        response = "âš  ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°"
        prediction = "Error"

    finally:
        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð»Ð¾Ð³Ð°
        log_data = {
            "timestamp": timestamp,
            **user_info,
            "text": text,
            "prediction": "Disaster" if prediction == 1 else "No disaster" if prediction == 0 else "Error"
        }

        try:
            log_request(log_data)
        except Exception as e:
            logger.error(f"ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ Ð›ÐžÐ“Ð˜Ð ÐžÐ’ÐÐÐ˜Ð¯: {str(e)}")

        await update.message.reply_text(response)


# ÐžÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    keyboard = [["/help"]]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    await update.message.reply_text(
        "ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ ÐºÐ°Ñ‚Ð°ÑÑ‚Ñ€Ð¾Ñ„Ð°Ñ….",
        reply_markup=reply_markup
    )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    keyboard = [["/help"]]
    await update.message.reply_text(
        "ðŸ“‹ ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°",
        reply_markup=ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    )


def main() -> None:
    application = Application.builder().token(TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.run_polling()


if __name__ == "__main__":
    print(f"|{TOKEN}|")
    main()